import pandas as pd
import subprocess
import os
import re
from collections import defaultdict
import csv


step_names =  ['DSB_background', 'Sample filter', 'Imputation', 'Downsample', 'Transcript filter', 'Cell filter', 'Integration', 'cluster filter']
### Cell filter -> DSB are within batches
### RNA normalization can go where? Just after Downsample?
### I'm thinking after Transcript Filter, though it seems my earlier SC pipeline normalized just before cell and feature filtering.


include: "/hpcdata/vrc/vrc1_data/douek_lab/snakemakes/SingleCell/Common_prep.py"
#include: "/hpcdata/vrc/vrc1_data/douek_lab/snakemakes/SingleCell/Snakefile"

### Panel info may be a panel name, or if multiple panels, a file with columns per panel, rows per feature and values 0 or 1 indicating membership.
#panel_info = config['panel_info']
#if(os.path.isfile(panel_info)):
#  panel_dat = pd.read_table(panel_info, sep =',')
#  panels = list(panel_dat.columns)
#  panels.remove('panel_prefix')
#else:
#  panels = [panel_info]
#print('Panel(s): ', panels)

### List of test variable names from the configuration file
#tests = [x.strip() for x in config['test'].split(',')]
#print(tests)
### Define stratifications
#strats = [x.strip() for x in config['stratifications'].split(':')]
#strat_list = ['All']
#if(len(strats) > 1):
#  strat_list = strat_list + [strats[0] + '-' + v.strip() for v in strats[1].split(',')]
#print('Stratifications: ')
#print(strat_list)

### Read sample sheet
sample_sheet = os.path.join(os.getcwd(), config['sample_sheet'])
samples = pd.read_table(sample_sheet, sep = ',').set_index('Sample_ID', drop = False)

### Read list of cluster comparisons to do
#cc_file = os.path.join(os.getcwd(), config['cluster_compare'])
#cluster_combos = []
#if os.path.exists(cc_file):
#  cc = pd.read_csv(cc_file)
#  print(cc)
#  cluster_combos = ['-'.join(list(row)) for index,row in cc.iterrows()]
#print(cluster_combos)

#batchs = list(set(samples[config['batch']]))
#print('N batches: ' + str(len(batchs)))

### For dynamic batches. Uses checkpoint 'set_batches', creates a list for input to rule 'Combine_batches'
def aggregate_rds_inputs(wildcards):
  checkpoint_output = checkpoints.set_batches.get(**wildcards).output[0]
  rna_rds = expand(results_dir + "batches/{i}/Cell_filtered.RDS", i = glob_wildcards(os.path.join(checkpoint_output, "{i}", "Sample_sheet.csv")).i)
  dsb_rds = expand(results_dir + "batches/{i}/DSB_normalized_data.RDS", i = glob_wildcards(os.path.join(checkpoint_output, "{i}", "Sample_sheet.csv")).i)
  return rna_rds + dsb_rds

def aggregate_txt_inputs(wildcards):
  checkpoint_output = checkpoints.set_batches.get(**wildcards).output[0]
  txt = expand(results_dir + "batches/{i}/Cell_filtered.txt", i = glob_wildcards(os.path.join(checkpoint_output, "{i}", "Sample_sheet.csv")).i)
  return txt

### If the last line of the second output of cluster_filters (Filters.txt) specifies that 0 cells were filtered, skip re-clustering
#def maybe_skip_second_cluster(wildcards):
#  cp = checkpoints.cluster_filter.get().output[1]
#  with open(cp) as f:
#    for line in f:
#      pass
#    last_line = line
#  if(bool(re.search('filtered,0', last_line))):
#    print('Skip second cluster.')
#    return results_dir + "Cluster_filtered.RDS"
#  else:
#    print('Do second cluster.')
#    return results_dir + "Clustered_again.RDS"
  
#def maybe_skip_annotation(do_annot):
#  if(do_annot):
#    out = results_dir + 'Mapped.RDS'
#  else:
#    out = results_dir + 'Processed_data.RDS'
#  return out

include: '/hpcdata/vrc/vrc1_data/douek_lab/snakemakes/SingleCell/Snakefile'

rule all:
  input: results_dir + 'App/Data.RData'
  #input: ['results/App/Data.RData'.format(panel=panel) for panel in panels]

### method options are MULTIseqDemux or Trough
rule Dehash:
  input:
    samples = sample_sheet,
    gtf = 'data/gtf.RDS'
  params:
    scripts = config['SC_scripts'],
    runs_dir = config['runs_dir'],
    project = config['project'],
    #threshs = "data/Dehash_threshs_{method}.csv",
    threshs = results_dir + "Dehash/Dehash_threshs_{method}.csv",
    dehash_dir = results_dir + 'Dehash/'
  resources: mem_mb=50000 
  output:
    #calls = "data/Dehash_calls_{method}.tsv",
    #threshs = "data/Dehash_threshs_{method}.csv",
    #pdf1 = "data/Dehash_feature_counts_{method}.pdf",
    #pdf2 = "data/Dehash_cell_counts_{method}.pdf"
    calls = results_dir + "Dehash/Dehash_calls_{method}.tsv",
    pdf1 = results_dir + "Dehash/Dehash_feature_counts_{method}.pdf",
    pdf2 = results_dir + "Dehash/Dehash_cell_counts_{method}.pdf"
  shell:
    """
    mkdir -p {params.dehash_dir}
    Rscript {params.scripts}/Dehash.R {input} '{params.runs_dir}' '{params.project}' '{wildcards.method}' '{params.threshs}' {output}
    """

print(list(dehash_calls_tsv.values()))
rule Dehash_method_comparison:
  input:
    samples = sample_sheet,
    call_files = list(dehash_calls_tsv.values())
    #thresh_files = dehash_threshs_tsv.values()
  params:
    scripts = config['SC_scripts'],
    runs_dir = config['runs_dir'],
    project = config['project'],
    method = config['dehash_method_comparisons'],
    thresh_files = list(dehash_threshs_csv.values())
  resources: mem_mb=50000
  output:
    results_dir + "Dehash/Dehash_comparisons_calls.pdf",
    results_dir + "Dehash/Dehash_comparisons_threshs.pdf",
    results_dir + "Dehash/Dehash_comparisons.csv"
  shell:
    "Rscript {params.scripts}/Dehash_method_comparison.R '{params.runs_dir}' '{params.project}' '{params.method}' {output} {input} {params.thresh_files}"

rule dehash_CellRanger_intersection:
  input:
    #calls = "data/Dehash_calls_{method}.tsv",
    calls = results_dir + "Dehash/Dehash_calls_{method}.tsv",
  params:
    scripts = config['SC_scripts'],
    method = config['dehash_method']
  output:
    #"data/Dehash_CRint_calls_{method}.tsv"
    results_dir + "Dehash/Dehash_CRint_calls_{method}.tsv"
  shell:
    "Rscript {params.scripts}/CellRanger_intersection.R {input} '{params.method}' {output}" 

print(dehash_CRint_calls_tsv[utilized_method_name])
rule dehash_to_sonar_input:
  input:
    samples = sample_sheet,
    #call_file = dehash_CRint_calls_tsv[config['dehash_method']]
    call_file = dehash_CRint_calls_tsv[utilized_method_name]
  params:
    scripts = config['SC_scripts'],
    project = config['project'],
    method = config['dehash_method']
  output:
    results_dir + 'For_SONAR.csv'
  shell:
    "Rscript {params.scripts}/sonar0.R {input} {params.project} {params.method} {output}"

rule Create_cells_seurat:
  input:
    samples = sample_sheet,
    calls = dehash_CRint_calls_tsv[utilized_method_name],
    comp = results_dir + "Dehash/Dehash_comparisons_threshs.pdf"
  params:
    scripts = config['CITESeq_scripts'],
    runs_dir = config['runs_dir'],
    project = config['project'],
    cell_type = config['cell_type'],
    results_dir = results_dir
  output:
    results_dir + "All_data.RDS",
    results_dir + "All_data.pdf"
  resources:
    mem_mb=30000
  shell:
    """
    mkdir -p {params.results_dir}
    Rscript {params.scripts}/Create_Seurat_RDS.R '{params.runs_dir}' '{params.project}' '{params.cell_type}' {input.samples} {input.calls} {output}
    """

### Move
### QC step 7
#rule prot_filter:
#  input:
#    seurat = results_dir + "Combined_batches.RDS",
#    samples = sample_sheet,
#    qc = QC_specs['step7']
#    [os.path.join(results_dir, Batch, 'Cell_filtered.txt') for Batch in batchs]
#  params:
#    script = config['CITESeq_scripts'],
#    batch_name = config['batch']
#  output:
#tch    results_dir + "RNA_cell_filtered.RDS",
#    results_dir + "RNA_filters.pdf",
#    results_dir + "Cell_filtered.txt"
#  shell:
#    "Rscript {params.script}/prot_filter.R {params.batch_name} {output} {input}"

### Simple regeneration of UMAP plots
### Currently assumes RNA and prot are present
rule UMAPs_unfiltered:
  input:
    "results/Clustered.RDS"
  params:
    script = config['CITESeq_scripts'],
  output:
    "results/UMAPs_unfiltered.pdf"
  shell:
    "Rscript {params.script}/UMAPs.R {input} {output}"
rule UMAPs:
  input:
    "results/Filtered_clustered.RDS"
  params:
    script = config['CITESeq_scripts'],
  output:
    "results/UMAPs.pdf"
  shell:
    "Rscript {params.script}/UMAPs.R {input} {output}"
    
rule WNNing:
  input:
    maybe_skip_second_cluster
  params:
    scripts = config['CITESeq_scripts'],
  output:
    results_dir + "Processed_data.RDS",
    results_dir + "WNN.pdf"
  resources:
    mem_mb=240000
  shell:
    "Rscript {params.scripts}/WNN.R {input} {output}"

rule CS_App_data:
  input:
    #results_dir + "Processed_data.RDS",
    #maybe_skip_annotation(config['species'], config['tissue']),
    'data/gtf.RDS',
    results_dir + "Cluster_DE/Singles.txt",
    maybe_skip_annotation(do_annot), ### Mapped.RDS or Processed_data.RDS
    expand(os.path.join(results_dir, 'Cluster_DE', 'One-all', "{assay}-{cluster_type}.RDS"), assay = assays_list, cluster_type = clusters_list),
    expand(os.path.join(results_dir, 'SubClusters', "{cluster}.RDS"), assay = assays_list, cluster = sub_clusters)
  params:
    scripts = config['CITESeq_scripts'],
    pdf_file = results_dir + 'SomeGenes.pdf',
    gene_file = config['gene_file'],
    project = config['project'],
    username = config['username'],
    server = config['server'],
    results_dir = results_dir
  output:
    results_dir + "App/Data.RData"
  resources:
    mem_mb=240000
  shell:
    """
    mkdir -p {params.results_dir}/App/
    cp {params.scripts}/App.R {params.results_dir}/App/
    cp {params.scripts}/../../../sc_functions.R {params.results_dir}/App/
    Rscript {params.scripts}/Create_app_data.R {output} '{params.pdf_file}' '{params.gene_file}' '{params.project}' '{params.username}' '{params.server}' {input}
    """

